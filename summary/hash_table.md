# 散列表( hash 表或则 哈希表)

## 基础知识

```shell
    1. 散列表是数组的扩展，用的是数组随机访问的特性，如果没有数组，就没有散列表
    2. 散列思想:
            参赛选手的编号叫作键（key）或者关键字(用它来标识一个选手),
            把参赛编号转化为数组下标的映射方法就叫作散列函数(“Hash 函数”,“哈希函数”)，
            而散列函数计算得到的值就叫作散列值（“Hash 值”,“哈希值”）
    3. 散列表用的是数组支持按下标随机访问其时间复杂度是 O(1) 的特性。通过散列函数把元素的键值映射为下标，然后将数据保存在对应下标中。
    　 要根据键值查询元素时，用同样的散列函数，将键值转化数组下标，从对应的数组下标中取数据。
    
    4. 装载因子(load factor) : 填入表中的元素个数 / 散列表的总长度, 装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降
    5. 散列表碰撞攻击: 通过构造数据，使得这些数据经过散列函数后都在同一个槽内，使之退化为单链表，查询的效率下降到 n 倍，
    　　　　　　　　　　如果散列表中有 10 万个数据，退化后的散列表查询的效率就下降了 10 万倍。更直接点说，
    　　　　　　　　　　如果之前运行 100 次查询只需要 0.1 秒，那现在就需要 1 万秒。这样就有可能因为查询操作消耗大量 CPU 或者线程资源，
    　　              导致系统无法响应其他请求，从而达到拒绝服务攻击（DoS）的目的
            
```

## 散列函数

```shell
    1. 散列函数设计的基本要求
        (1) 散列函数计算得到的散列值是一个非负整数, 因为数组下标是从 0 开始的
        (2) 如果 key1 = key2，那 hash(key1) == hash(key2)；
        (3) 如果 key1 ≠ key2，最好 hash(key1) ≠ hash(key2)，散列函数可以会存在冲突，
        　　要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的，像 MD5、SHA、CRC等哈希算法，
            也无法完全避免这种散列冲突。而且因为数组的存储空间有限，也会加大散列冲突的概率。
    2. 散列函数设计的好坏，决定散列表冲突的概率大小，也直接决定散列表的性能
            (1) 散列函数的设计不能太复杂, 太复杂会消耗很多计算时间，也间接影响到散列表的性能
            (2) 散列函数生成的值要尽可能随机并且均匀分布, 
                    随机是避免或者最小化散列冲突，均匀分布是出现冲突，散列到每个槽里的数据平均分布，不会出现某个槽内数据特别多的情况。
    3. 散列函数设计方法
            (1) 数据分析法, 例如手机号码前几位重复的可能性很大，但是后面几位就比较随机，我们可以取手机号的后四位作为散列值
            
```

## 装载因子过大

```shell
    1. 装载因子过大,会影响到插入查找的效率, 这时候需要动态扩容．
    2. 避免低效地扩容
            为了解决一次性扩容耗时过多的情况(其操作是先申请 2 倍空间于原来容量，在重新计算哈希值，将原来的散列表中数据搬到新的散列表中)，
            当装载因子到达阈值后，只申请新空间，但并不将老的数据搬移到新散列表中。当有新数据要插入时，将新数据插入新散列表中，
            并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程。
            经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样没有了集中的一次性数据搬移，
            插入操作就都变得很快。在这期间如果要查询数据，则先从新散列表中查找，如果没有找到，再从老的散列表中查找。
```

## 解决散列冲突

```shell
    1.开放寻址法 (open addressing)
            (1) 优点:
                    开放寻址法中散列表数据都是保存在数组中，可以有效地利用 CPU 缓存加快查询速度，同时要比链表法更方便序列化
            (2) 缺点:
                    删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据。而且所有的数据都存储在一个数组中，
                    比链表法来说，冲突的代价更高。
            (3) 当数据量比较小、装载因子小的时候，适合采用开放寻址法。
                 这也是 Java 中的 ThreadLocalMap 使用开放寻址法解决散列冲突的原因。
            方案一: 线性探测(Linear Probing)
                        插入操作:
                              在散列表中插入数据时，键值经过散列函数散列之后得到的哈希值(数组下标)已经被占用了，就从当前位置开始，
                              依次往后查找(步长为 1 )，看是否有空闲位置，直到找到为止。
                        查找操作:
                                通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。
                                如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找(步长为 1)。
                                如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。
                        删除操作:
                               将删除的元素，特殊标记为 deleted。当线性探测查找的时候，遇到标记为 deleted 的空间，
                               并不是停下来，而是继续往下探测(特殊标记为 deleted　这样是为了防止删除操作只是简单把元素置空，在查找时
                               刚好找到这个原来的位置(已被置空)，剩下就不继续查找)
                        
                        缺点: 
                              当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，
                              线性探测的时间就会越来越久。极端情况下，我们可能需要探测整个散列表，所以最坏情况下的时间复杂度为 O(n)。
                              同理，在删除和查找时，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据。
            方案二: 二次探测(Quadratic probing)
                        冲突时探测步长为线性的二次方，例如: 
                        数组下标序列就是 hash(key) + 0, hash(key) + 1 ^ 2, hash(key) + 2 ^ 2, hash(key) + 3 ^ 2
            方案三: 双重散列(Double hashing)
                        使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……
                        先用第一个散列函数，如果计算得到的存储位置(哈希值或则数组下标)已经被占用，再用第二个散列函数，
                        依次类推，直到找到空闲的存储位置
    2. 链表法
           在散列表中，每个“桶(bucket)”或者“槽(slot)”会对应一条链表，所有散列值相同的元素都放到相同槽位对应的链表中。
           当插入的时候，只需要通过散列函数计算出对应的散列槽位(数组下标)，将其插入到对应链表中即可，所以插入的时间复杂度是 O(1)。
           查找和删除也一样，先计算出哈希值，找到对应的桶，在该桶对应的链表中查找对应的元素
           
           (1) 优点:
                    链表法对内存的利用率比开放寻址法要高,链表法比开放寻址法其对应装载因子容忍度更高，只要散列函数的值随机均匀，
                    则查找时要比顺序查找效率高得多．
           (2) 缺点:
                    链表中的结点是零散分布在内存中的，不是连续的，对于执行效率而言，链表法要比开放寻址法执行效率低.
                    因为链表是要多余的空间来占用指针，所以对于比较小的对象而言，内存会消耗翻倍．
                    如果我们存储的是大对象，要存储的对象的大小远远大于一个指针的大小，那链表中指针的内存消耗在大对象面前就可以忽略
           (3) 其中链表可以用跳表、红黑树等动态数据结构替换，即使出现散列冲突，极端情况下，所有的数据都散列到同一个桶内(桶内有原先链表改为红黑树)，
           　　那最终退化成的散列表的查找时间也只不过是 O(logn)。
           (4) 链表法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。
            
```

## 设计散列表

```shell
    1. 设计一个合适的散列函数；
    2. 定义装载因子阈值，并且设计动态扩容策略；
    3. 选择合适的散列冲突解决方法
```

## 应用

```shell
    1. 实现 Word 文档中的单词拼写检查功能(不具备语法功能)
            用散列表来存储整个英文单词词典,再将输入的单词通过对应的哈希算法，看是否找到，找到则拼写正确，否则拼写错误.其中散列函数
            设计可以是将单词中每个字母的 ASCll 码值“进位”相加，然后再跟散列表的大小取模，作为散列值.例如
            　hash("nice")=(("n" - "a") * 26*26*26 + ("i" - "a")*26*26 + ("c" - "a")*26+ ("e"-"a")) % hash_size

    2. Java 中的 HashMap 散列表分析
            (1) HashMap 默认的初始大小是 16，如果事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，
                提高 HashMap 的性能
            (2) 装载因子和动态扩容, 最大装载因子默认是 0.75，当 HashMap 中元素个数超过 0.75 * capacity(capacity 表示散列表的容量)
                就会启动扩容，每次扩容都会扩容为原来的两倍
            (3) 散列冲突解决方法, HashMap 底层采用链表法来解决冲突,当冲突发送时其同一个桶的链表长度过长(默认超过 8), 
               利用红黑树快速增删改查的特点，提高 HashMap 的性能。当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表。
               在数据量较小的情况下，红黑树要维护平衡，比起链表来，性能上的优势并不明显。
            (4) 散列函数
                    hashcode 的随机性，加上移位异或算法，得到一个非常随机的hash值，再通过「除留余数法」
                    
                    int hash(Object key) {
                        int h = key.hashCode()；
                        return (h ^ (h >>> 16)) & (capitity -1); //capicity 表示散列表的大小 A % B = A & (B - 1)
                    }
                    
                    public int hashCode() {
                      int var1 = this.hash;
                      if(var1 == 0 && this.value.length > 0) {
                        char[] var2 = this.value;
                        for(int var3 = 0; var3 < this.value.length; ++var3) {
                          var1 = 31 * var1 + var2[var3];
                        }
                        this.hash = var1;
                      }
                      return var1;
                    }
    3. python的字典 dict 结构也是用 散列表
                    
```
